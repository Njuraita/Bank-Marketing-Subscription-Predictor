{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketting Subscription Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "#### **Problem Statement** \n",
    "The goal of this project is to build a predictive model that accurately determines the likelihood of a client subscribing to a term deposit based on various customer features. The bank's marketing campaigns heavily rely on effectively targeting customers who are more likely to subscribe to a term deposit. By leveraging machine learning techniques, the project seeks to improve the efficiency of these marketing campaigns and increase the conversion rate\n",
    "\n",
    "#### **Stakeholders:**\n",
    "     - Executive Officers (CEO)\n",
    "     - Marketing Officers (CMO) \n",
    "     - Data Aministrators (CDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior information we have been provided with is as below in the output of this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Relevant Information:\n",
      "\n",
      "The data is related with direct marketing campaigns of a banking institution.\n",
      "The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required,\n",
      "in order to access if the product (bank term deposit) would be (or not) subscribed.\n",
      "\n",
      "There are two datasets:\n",
      "1) bank-full.csv with all examples, ordered by date (from May 2008 to November 2010).\n",
      "2) bank.csv with 10% of the examples (4521), randomly selected from bank-full.csv.\n",
      "The smallest dataset is provided to test more computationally demanding machine learning algorithms (e.g. SVM).\n",
      "\n",
      "2. Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\n",
      "\n",
      "3. Number of Attributes: 16 + output attribute.\n",
      "\n",
      "4. Attribute information:\n",
      "\n",
      "Input variables:\n",
      "# bank client data:\n",
      "1 - age (numeric)\n",
      "2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
      "\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\")\n",
      "3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
      "4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
      "5 - default: has credit in default? (binary: \"yes\",\"no\")\n",
      "6 - balance: average yearly balance, in euros (numeric)\n",
      "7 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
      "8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
      "# related with the last contact of the current campaign:\n",
      "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\")\n",
      "10 - day: last contact day of the month (numeric)\n",
      "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
      "12 - duration: last contact duration, in seconds (numeric)\n",
      "# other attributes:\n",
      "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
      "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
      "15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
      "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
      "\n",
      "Output variable (desired target):\n",
      "17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
      "\n",
      "5. Missing Attribute Values: None\n"
     ]
    }
   ],
   "source": [
    "# Load names file\n",
    "with open(r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Bank-Marketing-Subscription-Predictor\\data\\bank-names.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Other than what is provided in the code above about the data there is important information not covered. The total number of datasets are for and below is the explanation\n",
    "- - bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010),   very close to the data analyzed. \n",
    "- - bank-additional.csv with 10% of the examples (4119), (randomly selected from 1), and 20 inputs. \n",
    "- - bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs).  \n",
    "- - bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). \n",
    "- We can deduce that this is a classification problem and this will inform the flow of the project that is ; the feature engeneering,the evaluation metrics, the models that are likely to work best with such a project etc \n",
    "- That being noted, as the project progresses, **key insights** are noted below each task performed for better project flow  \n",
    "\n",
    "#### **Key Metrics and Success Criteria**\n",
    "     1. Acuracy-The Model should have an accuracy score of 85% (On balanced data).Good models are expected to have an accuracy score of >0.80 or 80%\n",
    "     2. Threshold for precision and Recall - The model should achieve a precision and recall at least 80%. This assures that the model is reliable in predicting\n",
    "     3. Minimum F1 Score- The F1 score should be atleast 0.75. This balances the trade offs between precision and recalls, indicating the model performs well even if the class distribution is imbalanced\n",
    "     4. AUC-ROC Score- This should be atleast 0.85. A high AUC-ROC score indicates that the model is effective in distinguishing subscribers to non subscribers\n",
    "     5. Confusion Matrix - The number of False Negatives (FN) should be lower to ensure that most of the subscription cases are identified\n",
    "     \n",
    "    \n",
    "#### **Hypothesis**\n",
    "\n",
    "#### Null Hypothesis\n",
    "\n",
    "#### Alternative Hpothesis\n",
    "\n",
    "#### Analytical Questions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data\n",
    "bank_additional_full = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Bank-Marketing-Subscription-Predictor\\data\\bank-additional-full.csv\", delimiter=\";\")\n",
    "bank_additional = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Bank-Marketing-Subscription-Predictor\\data\\bank-additional.csv\", delimiter=\";\")\n",
    "bank = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Bank-Marketing-Subscription-Predictor\\data\\bank-full.csv\", delimiter=\";\")\n",
    "bank_full = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Bank-Marketing-Subscription-Predictor\\data\\bank.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_additional_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education default  housing     loan  \\\n",
       "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
       "1   39     services   single        high.school      no       no       no   \n",
       "2   25     services  married        high.school      no      yes       no   \n",
       "3   38     services  married           basic.9y      no  unknown  unknown   \n",
       "4   47       admin.  married  university.degree      no      yes       no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0   cellular   may         fri  ...         2    999         0  nonexistent   \n",
       "1  telephone   may         fri  ...         4    999         0  nonexistent   \n",
       "2  telephone   jun         wed  ...         1    999         0  nonexistent   \n",
       "3  telephone   jun         fri  ...         3    999         0  nonexistent   \n",
       "4   cellular   nov         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0         -1.8          92.893          -46.2      1.313       5099.1  no  \n",
       "1          1.1          93.994          -36.4      4.855       5191.0  no  \n",
       "2          1.4          94.465          -41.8      4.962       5228.1  no  \n",
       "3          1.4          94.465          -41.8      4.959       5228.1  no  \n",
       "4         -0.1          93.200          -42.0      4.191       5195.8  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bank Additional Full:\n",
      "(41188, 21)\n",
      "-----------------------------------------------------------------------------------------\n",
      "Bank Additional:\n",
      "(4119, 21)\n",
      "-----------------------------------------------------------------------------------------\n",
      "Bank:\n",
      "(45211, 17)\n",
      "----------------------------------------------------------------------------------------- \n",
      "Bank Full:\n",
      "(4521, 17)\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shapes = f\"\"\"\n",
    "Bank Additional Full:\n",
    "{bank_additional_full.shape}\n",
    "-----------------------------------------------------------------------------------------\n",
    "Bank Additional:\n",
    "{bank_additional.shape}\n",
    "-----------------------------------------------------------------------------------------\n",
    "Bank:\n",
    "{bank.shape}\n",
    "----------------------------------------------------------------------------------------- \n",
    "Bank Full:\n",
    "{bank_full.shape}\n",
    "-----------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "print (shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4119 entries, 0 to 4118\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             4119 non-null   int64  \n",
      " 1   job             4119 non-null   object \n",
      " 2   marital         4119 non-null   object \n",
      " 3   education       4119 non-null   object \n",
      " 4   default         4119 non-null   object \n",
      " 5   housing         4119 non-null   object \n",
      " 6   loan            4119 non-null   object \n",
      " 7   contact         4119 non-null   object \n",
      " 8   month           4119 non-null   object \n",
      " 9   day_of_week     4119 non-null   object \n",
      " 10  duration        4119 non-null   int64  \n",
      " 11  campaign        4119 non-null   int64  \n",
      " 12  pdays           4119 non-null   int64  \n",
      " 13  previous        4119 non-null   int64  \n",
      " 14  poutcome        4119 non-null   object \n",
      " 15  emp.var.rate    4119 non-null   float64\n",
      " 16  cons.price.idx  4119 non-null   float64\n",
      " 17  cons.conf.idx   4119 non-null   float64\n",
      " 18  euribor3m       4119 non-null   float64\n",
      " 19  nr.employed     4119 non-null   float64\n",
      " 20  y               4119 non-null   object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 675.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4521 non-null   int64 \n",
      " 1   job        4521 non-null   object\n",
      " 2   marital    4521 non-null   object\n",
      " 3   education  4521 non-null   object\n",
      " 4   default    4521 non-null   object\n",
      " 5   balance    4521 non-null   int64 \n",
      " 6   housing    4521 non-null   object\n",
      " 7   loan       4521 non-null   object\n",
      " 8   contact    4521 non-null   object\n",
      " 9   day        4521 non-null   int64 \n",
      " 10  month      4521 non-null   object\n",
      " 11  duration   4521 non-null   int64 \n",
      " 12  campaign   4521 non-null   int64 \n",
      " 13  pdays      4521 non-null   int64 \n",
      " 14  previous   4521 non-null   int64 \n",
      " 15  poutcome   4521 non-null   object\n",
      " 16  y          4521 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n",
      "\n",
      "Bank Additional Full:\n",
      "None\n",
      "-----------------------------------------------------------------------------------------\n",
      "Bank Additional:\n",
      "None\n",
      "-----------------------------------------------------------------------------------------\n",
      "Bank Full:\n",
      "None\n",
      "----------------------------------------------------------------------------------------- \n",
      "Bank :\n",
      "None\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infos = f\"\"\"\n",
    "Bank Additional Full:\n",
    "{bank_additional_full.info()}\n",
    "-----------------------------------------------------------------------------------------\n",
    "Bank Additional:\n",
    "{bank_additional.info()}\n",
    "-----------------------------------------------------------------------------------------\n",
    "Bank Full:\n",
    "{bank_full.info()}\n",
    "----------------------------------------------------------------------------------------- \n",
    "Bank :\n",
    "{bank.info()}\n",
    "-----------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "print (infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bank Additional Full:\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
      "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------------------------------------------\n",
      "Bank Additional:\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
      "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------------------------------------------\n",
      "Bank Full:\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'y'],\n",
      "      dtype='object')\n",
      "----------------------------------------------------------------------------------------- \n",
      "Bank :\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'y'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = f\"\"\"\n",
    "Bank Additional Full:\n",
    "{bank_additional_full.columns}\n",
    "-----------------------------------------------------------------------------------------\n",
    "Bank Additional:\n",
    "{bank_additional.columns}\n",
    "-----------------------------------------------------------------------------------------\n",
    "Bank Full:\n",
    "{bank_full.columns}\n",
    "----------------------------------------------------------------------------------------- \n",
    "Bank :\n",
    "{bank.columns}\n",
    "-----------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "print (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Merge the Train Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (260746689.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    Bank_anaysis_data = pd.concat([**, **], ignore_index=True)\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Combine DataFrames\n",
    "Bank_anaysis_data = pd.concat([**, **], ignore_index=True)\n",
    "\n",
    "***.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data consistency and analysis\n",
    "\n",
    "***.replace(True, 'Yes', inplace=True)\n",
    "***.replace(False, 'No', inplace=True)\n",
    "\n",
    "***.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change *** to float \n",
    "\n",
    "***['column**'] = pd.to_numeric(***['column**'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates \n",
    "****.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values with their percentages \n",
    "***.isnull().sum().to_frame('Null Count').assign(Percentage=lambda x: (x['Null Count'] / len(churn_prime)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in each column\n",
    "\n",
    "for column in columns:\n",
    "    print(f'{column}')\n",
    "    print(f'There are {***[column].unique().size} unique values')\n",
    "    print(f'These are {***[column].unique()}')\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical  Analysis of numeric values\n",
    "\n",
    "***.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview Analysis of categorical columns \n",
    "\n",
    "***.describe(include= 'object').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EDA**  (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Numerical Columns EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Numerical Feature\n",
    "***.hist(figsize= (14,10),grid=False, color='skyblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.kdeplot(***['column**'])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot for multiple columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(churn_prime[['tenure', 'MonthlyCharges']],  whis=1.5)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Box Plot of tenure, Monthly Charges')\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Distribution')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='Contract', y='MonthlyCharges', data=churn_prime, palette='muted')\n",
    "plt.title('Monthly Charges by Contract Type')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Monthly Charges')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=churn_prime, palette='muted')\n",
    "plt.title('Monthly Charges by Churn Customers')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Monthly Charges')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Maltivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "numeric_df = churn_prime.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(churn_prime[['MonthlyCharges', 'TotalCharges', 'tenure', 'Churn']], hue='Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Categorical Columns EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Distribution and Counts for Categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart for the 'Contract' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(churn_prime, x='Churn', order=churn_prime['Churn'].value_counts().index)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Churn Count')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Churn column is imbalanced (we have class imbalance), with more 'No' than 'Yes' values. This affects model training, leading to biased predictions. Consider using techniques like SMOTE (Synthetic Minority Over-sampling Technique) or adjusting class weights to balance the dataset during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart for the 'Contract' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(churn_prime, x='Contract', order=churn_prime['Contract'].value_counts().index)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Bar Chart of Contract Types')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the contracts column which will be our focus for the hypothesis we did a bar plot- and realise most customers are on the month to month subscription contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart for the 'Contract' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(churn_prime, x='InternetService', order=churn_prime['InternetService'].value_counts().index)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Bar Chart of InternetService Distribution')\n",
    "plt.xlabel('InternetService')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart for the 'Contract' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(churn_prime, x='PaymentMethod', order=churn_prime['PaymentMethod'].value_counts().index)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Bar Chart of PaymentMethod Distribution')\n",
    "plt.xlabel('PaymentMethod')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hypothesis Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_train_chi = churn_prime.copy()\n",
    "\n",
    "# Drop the row with the unknown value from the Churn column\n",
    "df_train_chi.drop(index=2988, inplace=True)\n",
    "df_train_chi.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop 'customerID' column as it is not needed for analysis\n",
    "df_train_chi.drop(columns=['customerID'], axis=1, inplace=True)\n",
    "\n",
    "# Convert Churn to binary\n",
    "df_train_chi['Churn'] = df_train_chi['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Replace invalid TotalCharges with NaN\n",
    "df_train_chi['TotalCharges'] = pd.to_numeric(df_train_chi['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "num_columns = df_train_chi.select_dtypes(include=['number']).columns\n",
    "cat_columns = df_train_chi.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values for numerical columns\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "df_train_chi[num_columns] = imputer_num.fit_transform(df_train_chi[num_columns])\n",
    "\n",
    "# Impute missing values for categorical columns\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df_train_chi[cat_columns] = imputer_cat.fit_transform(df_train_chi[cat_columns])\n",
    "\n",
    "# Create contingency table for Churn and Contract\n",
    "contingency_table = pd.crosstab(df_train_chi['Churn'], df_train_chi['Contract'])\n",
    "\n",
    "# Perform Chi-Square Test of Independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Output the results\n",
    "print(\"Chi-Square Test\")\n",
    "print(\"----------------\")\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "\n",
    "# Interpret the result based on the p-value\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis: This means there is a significant difference in churn rates among customers with different contract types.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: This means there is no significant difference in churn rates among customers with different contract types.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The chi-square test was utilized to examine whether there are significant variations in churn rates based on different contract types within the Telco dataset\n",
    "- With a chosen significance level (alpha) of 0.05, the extremely low p-value (3.62e-192) obtained from the test indicates a robust rejection of the null hypothesis.\n",
    "- Consequently, we reject the null hypothesis that there is no significant difference in churn rates across various contract types.\n",
    "- This statistical finding provides compelling evidence that contract type plays a critical role in influencing churn rates among Telco customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Answering Analytical Questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling misssing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime['TotalCharges'].fillna(churn_prime['TotalCharges'].median(), inplace=True) # TotalCharges column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_categ = ['MultipleLines', 'OnlineSecurity', 'OnlineBackup',               #For missing values in categorical columns \n",
    "                       'DeviceProtection', 'TechSupport', 'StreamingTV', \n",
    "                       'StreamingMovies', 'Churn']\n",
    "\n",
    "for col in miss_categ:\n",
    "    mode_val = churn_prime[col].mode()[0]                                      \n",
    "    churn_prime[col].fillna(mode_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert churn_prime to csv for Power Bi Visualisation before further Modeling\n",
    "\n",
    "churn_prime.to_csv('churn_prime.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop the Cutomer Id Column it doe not have any statistical  or computational significance and has too many unknown categories  that will affect the encoding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime = churn_prime.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prime.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Split data to X and y (Input and Output variables )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input variables\n",
    "\n",
    "X= churn_prime.drop ('Churn', axis= 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output variable / target variable \n",
    "y= churn_prime['Churn']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset exhibits a significant class imbalance, where instances labeled as \"No\" (indicating non-churn) outnumbers instances labeled as \"Yes\" (indicating churn) by a considerable margin. Addressing this imbalance is crucial as it can hinder the model's ability to effectively predict the minority class, which in this case is \"Yes\" or churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data to categorical and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns= X.select_dtypes('number').columns\n",
    "numerical_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns= X.select_dtypes('object').columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a lable encoder for y because its not a 2 dimentional array \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the target variable\n",
    "y_train_encoded= encoder.fit_transform(y_train)\n",
    "y_test_encoded= encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness to determine which scaler to use \n",
    "X.select_dtypes('number').skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descison\n",
    "Standard scaler is disqualified as our data is not anything close to a bell shape (being evenly distributed)\n",
    "MinMax scaller is diqualified as our data has outliers \n",
    "We use Robust Scaler due to the biases in X train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use Quantile transformer as it transform our data to a close to a bell shape-where data is evenly distributed and mean is equal to median which is equal to mode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline= Pipeline(steps=[ \n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('QuantileTransformation', QuantileTransformer ()),\n",
    "])\n",
    "\n",
    "categorical_pipeline= Pipeline([\n",
    "   ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "   ('encoder', OneHotEncoder()),\n",
    "    \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num_pipeline', numeric_pipeline, numerical_columns),\n",
    "    ('cat_pipeline', categorical_pipeline, categorical_columns),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modeling & Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on unbalanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('SVM', SVC(probability=True, random_state=42)),\n",
    "    ('GBM', GradientBoostingClassifier(random_state=42)),\n",
    "    ('Neural Network', MLPClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "\n",
    "# Arrays to store individual model predictions and their probabilities\n",
    "model_predictions = {}\n",
    "model_probabilities = {}\n",
    "\n",
    "# Store confusion matrices for each model\n",
    "confusion_matrices = {}\n",
    "\n",
    "for model_name, classifier in models:\n",
    "    # Define the pipeline with the classifier\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Store predictions and probabilities\n",
    "    model_predictions[model_name] = y_pred\n",
    "    model_probabilities[model_name] = y_prob\n",
    "\n",
    "    # Store confusion matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "    confusion_matrices[model_name] = cm\n",
    "\n",
    "    # Evaluate model performance with classification report\n",
    "    print(model_name)\n",
    "    print(classification_report(y_test_encoded, y_pred, target_names=['No', 'Yes']))  # Add target_names for class labels\n",
    "    print('=' * 50)\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_test_encoded, y_prob)\n",
    "\n",
    "    # Print ROC AUC score\n",
    "    print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "    print('=' * 50)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the models performance we can deduce that class imbalance is skewing model performance metrics towards the majority class (\"No\")\n",
    "- Moving forward we will address class imbalance through techniques like SMOTE and fine-tuning models to improved F1-scores, particularly for predicting churn instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the confusion matrix and AUC ROC Curve for our Imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert confusion matrices to DataFrame\n",
    "df_scores = pd.DataFrame.from_dict({model_name: [conf_matrix] for model_name, conf_matrix in confusion_matrices.items()}, orient='index', columns=['confusion_matrix'])\n",
    "df_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(df_scores, figsize=(15, 8), ncols=3):\n",
    "    nrows = int(np.ceil(len(df_scores) / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (model_name, row) in enumerate(df_scores.iterrows()):\n",
    "        conf_matrix = row['confusion_matrix']\n",
    "        ax = axes[i]\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Not Churn', 'Churn'], yticklabels=['Not Churn', 'Churn'], ax=ax)\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "        ax.set_title(f'Confusion Matrix - {model_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrices(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC AUC curve for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over each model's probabilities and plot ROC curve\n",
    "for model_name, y_prob in model_probabilities.items():\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test_encoded, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot random guessing line\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on balanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('SVM', SVC(probability=True, random_state=42)),\n",
    "    ('GBM', GradientBoostingClassifier(random_state=42)),\n",
    "    ('Neural Network', MLPClassifier(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_table =pd.DataFrame(columns=['Model','Accuracy', 'Precision', 'Recall', 'F1_Score'])\n",
    "balanced_pipeline= {}\n",
    " \n",
    "for model_name, classifier in models:\n",
    "   \n",
    "    pipeline = imbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('OverSampler', SMOTE(random_state=42)),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    " \n",
    "    pipeline.fit(X_train,y_train_encoded)\n",
    "   \n",
    "    balanced_pipeline [model_name]= pipeline\n",
    " \n",
    "    y_pred = pipeline.predict(X_test)\n",
    " \n",
    "   \n",
    "    balanced_metrics= classification_report(y_test_encoded, y_pred, output_dict=True)\n",
    " \n",
    "    accuracy= balanced_metrics['accuracy']\n",
    "    precision = balanced_metrics['weighted avg']['precision']\n",
    "    recall = balanced_metrics['weighted avg']['recall']\n",
    "    f1 = balanced_metrics['weighted avg']['f1-score']\n",
    " \n",
    "    balanced_table.loc[len(balanced_table)]= [model_name, accuracy, precision, recall,f1]\n",
    " \n",
    "balanced_table.sort_values(by='F1_Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After balancing Data we can notice an improvement in the F1 Scores of the Models With all models meeting the threshold creteria of 0.75 apart from KNN. \n",
    "- The best performing are Radom Forest and GBM with an F1 score of 0.791 and 0.790 respectively\n",
    "- The fact that recall matches accuracy for all models suggests that your data is well-balanced across classes. This is a good sign, indicating that the balancing technique (SMOTE) has been effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View balanced data pipelines \n",
    "balanced_pipeline ['Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(balanced_pipeline, X_test, y_test_encoded, figsize=(15, 8), ncols=3):\n",
    "    nrows = int(np.ceil(len(balanced_pipeline) / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (model_name, pipeline) in enumerate(balanced_pipeline.items()):\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "        \n",
    "        ax = axes[i]\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Not Churn', 'Churn'], yticklabels=['Not Churn', 'Churn'], ax=ax)\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "        ax.set_title(f'Confusion Matrix - {model_name}')\n",
    "    \n",
    "    # Remove any unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrices(balanced_pipeline, X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC AUC Curve for balanced pipeline\n",
    "def plot_roc_auc_curves(balanced_pipeline, X_test, y_test_encoded, figsize=(10, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Iterate over each model in the balanced pipeline\n",
    "    for model_name, pipeline in balanced_pipeline.items():\n",
    "        # Get predicted probabilities\n",
    "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Compute ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test_encoded, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    # Plot random guessing line\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "    # Set plot properties\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_auc_curves(balanced_pipeline, X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Findings:**\n",
    "\n",
    "**Model Performance Metrics:**\n",
    "\n",
    "- Accuracy- All models achieve relatively high accuracy scores ranging from 0.686 to 0.791. This indicates that they perform well in overall prediction correctness on balanced data\n",
    "-The highest performing being Random Forest with 0.790. But our target was >0.80\n",
    "\n",
    "\n",
    "- Precision- Measures how many of the predicted positive instances (churn) are actually positive\n",
    "-Logistic Regression and GBM show the highest precision scores around 0.808 and 0.802, respectively. Meeting the set threshold of >0.80\n",
    "\n",
    "\n",
    "- Recall: Reflects how many of the actual positive instances (churn) were predicted correctly\n",
    "-Random Forest achieves the highest recall score at 0.790 followed by GBM 0.784. Both do not meet threshold of >0.80\n",
    "\n",
    "\n",
    "\n",
    "- F1-score: Balances the trade-off between precision and recall, providing a single metric to evaluate model performance\n",
    "-Random Forest achieves the highest F1-score of 0.791, closely followed by GBM at 0.790 meeting the threshold of atleast 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Comparison and Recommendations**\n",
    "\n",
    "Random Forest and GBM consistently perform well across all metrics (accuracy, precision, recall, and F1-score). They are particularly robust in maintaining high F1-scores, suggesting effective balance between identifying churn cases and minimizing false positives.\n",
    "\n",
    "Logistic Regression and SVM also demonstrate strong performance with high precision scores, making them reliable choices for applications where precision in predicting churn is critical.\n",
    "\n",
    "Neural Network shows competitive performance but slightly lower precision compared to other models, indicating potential for further optimization or tuning.\n",
    "\n",
    "KNN exhibits the lowest recall among the models, which suggests it may struggle more with correctly identifying churn cases, especially in situations where recall is crucial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "The ensemble methods (Random Forest and GBM) stand out for their balanced performance across all metrics on balanced data. They are recommended for applications where F1 Score is the highest consideration like in this case. And therefore moving forwward we will fine tune this 2 to ensure maximum performance and the one with best performance we will use to test our test dataset\n",
    "\n",
    "Logistic Regression and SVM offer strong precision and are suitable for scenarios prioritizing precision in churn prediction.\n",
    "\n",
    "Neural Network shows promise but may benefit from further fine-tuning to improve precision and overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving our models for future use before the hyperparameter tuning as after tuning we realize that the scores reduce. In any project the scores before hyperparameter tuning can be used if the hyperparameter runing underperforms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier\n",
    "gbm_model = GradientBoostingClassifier\n",
    "svm_model = SVC\n",
    "\n",
    "# Create a folder named 'models' if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save the Random Forest model\n",
    "joblib.dump(rf_model, 'models/random_forest_model.joblib')\n",
    "\n",
    "# Save the GBM model\n",
    "joblib.dump(gbm_model, 'models/gbm_model.joblib')\n",
    "\n",
    "# Save the SVM model\n",
    "joblib.dump(svm_model, 'models/svm_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Perform Hyperparameter Tuning** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For this we selected the top performing models which are GBM and Random Forest Classification and see which one best performs after hyperparameter tuning in order to  pick the best performing model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-GBM HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingClassifier(**params, random_state=42)\n",
    "    \n",
    "    pipeline = imbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('oversampler', SMOTE(random_state=42)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        score = cross_val_score(pipeline, X_train, y_train_encoded, cv=5, scoring='f1_weighted', error_score='raise').mean()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in trial with parameters: {params}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return float('-inf')  # Return a very low score to indicate failure\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Create and run the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_f1_score = study.best_value\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", best_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations \n",
    "- The error message Error messages in the trials was later reaslised is because of the 'max_features' parameter was set to 'auto', which is not a valid option for the cross_val_score function in scikit-learn. And we'll be moving to correct this moving forward\n",
    "\n",
    "- Optimization Progress: Despite encountering errors in some trials, the study continued to run and completed all 100 trials as specified (n_trials=100).\n",
    "\n",
    "- The best F1-score observed during the study was 0.794, achieved in Trial 63 which was a slight improvement from 0.790"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-RANDOM FOREST HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    pipeline = imbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('oversampler', SMOTE()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    score = cross_val_score(pipeline, X_train, y_train_encoded, cv=5, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_f1_score = study.best_value\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", best_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "- Trial Number: Trial 99 indicates that this was the 99th trial conducted during the optimization process.\n",
    "- Trial Result: The F1-score observed for this trial was 0.635314351632384.\n",
    "- Trial Parameters: The hyperparameters tested during this trial were {'n_estimators': 335, 'max_depth': 9}.\n",
    "- Best Trial: The best F1-score observed overall throughout all trials was 0.6424022851349124, achieved in Trial 40.\n",
    "\n",
    "- From an initial F1 Score of 0.791 to 0.644 is a drop we will be adjusting the hyperparameters for better performance of the tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Challanges and Moving Forward**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The only Major Challange was with the hyperparameter tunings of our 2 best performing models which we will seek to work it out with the best hyperparameters so that we can move forward to sellecting the best model for our test data\n",
    "- Other Challanges were learning oportnities.\n",
    "- We will also be exporting core machine learning Components for future use in other projects \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exporting the Models for use in making our Multipages web based APP**\n",
    "- The two models will be\n",
    " \n",
    "-GBM\n",
    "\n",
    "-Random forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
